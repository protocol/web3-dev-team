{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This is a sample notebook for grabbing all the Github event data that the ecosystem dashboard has.\n",
    "\n",
    "This is useful if you want to analyze GitHub actions beyond opening PRs and issues.  It will also show comments, PR/issue closing, etc.\n",
    "\n",
    "This was originally put together to help with identifying top contributors on GitHub that should likely be invited to IPFS Camp 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import ecosystem_dashboard_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_date = datetime.date.today()\n",
    "report_date_str = report_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "from datetime import date\n",
    "analysis_start_date = date(2022, 9, 11) # Adjust for how far back you want to look\n",
    "number_of_days = (report_date - analysis_start_date).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"payload\" field add a bunch of data that we don't need so we strip it out to make the json more wieldly to consume\n",
    "def payload_filter(x): \n",
    "    del x[\"payload\"]\n",
    "    return x\n",
    "for ecosystem in [\"ipfs\"]: # You could add \"filecoin\"\n",
    "    for org in [\"ipfs\", \"ipfs-shipyard\"]:\n",
    "        events_path = f\"{ecosystem}-{org}-events-{report_date_str}.json\"\n",
    "        ecosystem_dashboard_utils.dump_api(unpaginated_url=f\"https://{ecosystem}.ecosystem-dashboard.com/events.json?range={number_of_days}&org={org}&\", output_path=events_path, filter=payload_filter, page_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report_date_str = \"2022-05-19\"\n",
    "df = pd.DataFrame()\n",
    "for ecosystem in [\"ipfs\"]:\n",
    "    for org in [\"ipfs\", \"ipfs-shipyard\"]:\n",
    "        events_path = f\"{ecosystem}-{org}-events-{report_date_str}.json\"\n",
    "        ecosystem_df = pd.read_json(events_path, orient='records')\n",
    "        if ecosystem_df.size == 0:\n",
    "            continue\n",
    "        ecosystem_df = ecosystem_df.set_index(\"github_id\")\n",
    "        df = pd.concat([df, ecosystem_df])\n",
    "\n",
    "# Remove duplciate event.\n",
    "# This is needed since there are duplciate repositories in filecoin and ipfs ecosystem dashboards.\n",
    "# https://stackoverflow.com/questions/13035764/remove-pandas-rows-with-duplicate-indices\n",
    "df = df[~df.index.duplicated(keep='first')]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"event/action\"] = df.apply(lambda x: x[\"event_type\"] + \"/\" + x[\"action\"] if x[\"action\"] else x[\"event_type\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_col_names = [\n",
    "    'org',\n",
    "    'repository_full_name',\n",
    "    'actor',\n",
    "    'event/action',\n",
    "]\n",
    "p2_col_names = df.columns.to_list()\n",
    "for p1_col_name in p1_col_names:\n",
    "    p2_col_names.remove(p1_col_name)\n",
    "\n",
    "ordered_col_names = []\n",
    "ordered_col_names.extend(p1_col_names)\n",
    "ordered_col_names.extend(p2_col_names)\n",
    "ordered_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[ordered_col_names]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"events-combined-cleaned-{report_date_str}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output\n",
    "You now have tabular data for each event, which makes it easy to create pivot tables to summarize how many actions a given user took."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
