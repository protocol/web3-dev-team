{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "This notebook takes Ecosystem Dashbaord dumps of Github event data and:\n",
    "1. Merges them (as may want to query different data ranges or different database instances as we have IPFS, Filecoin, and libp2p instances)\n",
    "2. Deduplicates them (as there is often depulicate events across the IPFS, Filecoin, and libp2p instances)\n",
    "3. Cleans them up (as the github event types and actions aren't the most intuitive or concicse)\n",
    "4. Adds additional data (tagging data with YYYYMM or YearQuarter is helpful for summary)\n",
    "5. Exports to a more useful form of showing a monthly rollup of how many github actions a given actor took in a given month/repo.\n",
    "\n",
    "This allows for easy import to do further analysis/summary in places like Google Sheets.  \n",
    "@biglep has been publishing to https://docs.google.com/spreadsheets/d/1jR6ueqrcdg6CYUvV3ibVWMjkGKj5WlU8ysuCO0TrHvo/edit?usp=sharing\n",
    "\n",
    "This data can be useful for getting insight into github activity in our repos.  @biglep has found this useful for:\n",
    "1. understanding at a high level who some of our contributors are and how they're changing\n",
    "2. getting a pulse at performance review time on where various team members have been contributing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Query\n",
    "Ideally this notebook should do the notebook queries directly, but at least as of 2023-06-19, biglep@ used his previous Postgres connections setup for `pgAdmin` and took dumps from there.\n",
    "\n",
    "The query being run was:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    github_id,\n",
    "    actor,\n",
    "    event_type,\n",
    "    action,\n",
    "    org,\n",
    "    repository_full_name,\n",
    "    created_at,\n",
    "    core,\n",
    "    bot,\n",
    "    pmf\n",
    "FROM\n",
    "    events\n",
    "WHERE\n",
    "    -- adjust the dates as needed\n",
    "    created_at >= DATE '2023-01-01'\n",
    "    AND created_at < DATE '2023-06-15'\n",
    "    AND org IN (\n",
    "        -- These are PL's \"core\" orgs\n",
    "        'multiformats',\n",
    "        'ipld',\n",
    "        'libp2p',\n",
    "        'ipfs',\n",
    "        'ipfs-examples',\n",
    "        'ipfs-shipyard',\n",
    "        'ipfs-inactive',\n",
    "        'ipfs-cluster',\n",
    "        'ipni',\n",
    "        'protocol',\n",
    "        'web3-storage',\n",
    "        'nftstorage',\n",
    "        'ProtoSchool',\n",
    "        'pl-strflt',\n",
    "        'plprobelab',\n",
    "        'application-research',\n",
    "        'filecoin-project',\n",
    "        'filecoin-shipyard',\n",
    "        'testground'\n",
    "    )\n",
    "    AND event_type IN (\n",
    "        -- https://docs.github.com/en/developers/webhooks-and-events/events/github-event-types\n",
    "        'IssueCommentEvent',\n",
    "        'IssuesEvent',\n",
    "        'PullRequestEvent',\n",
    "        'PullRequestReviewEvent',\n",
    "        'PullRequestReviewCommentEvent',\n",
    "        'ReleaseEvent'\n",
    "    )\n",
    "    AND actor NOT LIKE '%bot%'\n",
    "    AND actor NOT LIKE '%codecov%';\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "The skeleton of this code was generated from ChatGPT and modified from there.\n",
    "It assumes the .csv files from SQL dumps all live in an input directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "report_date = datetime.date.today()\n",
    "report_date_str = report_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Specify the directory paths for input and output\n",
    "input_directory = 'data/ecosystem-dashboard-github-event-dumps-from-sql'\n",
    "output_directory = f\"{input_directory}/output\"\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(input_directory)\n",
    "\n",
    "# Iterate over each file\n",
    "for file_name in files:\n",
    "    # Check if the item is a CSV file\n",
    "    file_path = os.path.join(input_directory, file_name)\n",
    "    if os.path.isfile(file_path) and file_path.endswith(\".csv\"):\n",
    "        # Open the file\n",
    "        print(f\"Reading {file_name}\")\n",
    "        temp_df = pd.read_csv(file_path, index_col='github_id')\n",
    "        print(f\"Read {file_name} with {len(temp_df)} rows\")\n",
    "        df = pd.concat([df, temp_df])\n",
    "\n",
    "# Deduplicate the rows based on the index (github_id)\n",
    "print(f\"Concatenated size: {len(df)} rows\")\n",
    "df = df[~df.index.duplicated(keep='first')]\n",
    "print(f\"Deduplicated size: {len(df)} rows\")\n",
    "\n",
    "# Convert 'created_at' column to datetime format\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# Add 'Year Month' column in 'YYYYMM' format\n",
    "df['year_month'] = df['created_at'].dt.strftime('%Y%m')\n",
    "\n",
    "# Add 'Year Quarter' column\n",
    "df['year_quarter'] = df['created_at'].dt.to_period('Q')\n",
    "\n",
    "# Create 'repository_name' column by extracting repository name\n",
    "df['repository_name'] = df['repository_full_name'].str.split('/').str.get(1)\n",
    "\n",
    "mapping_to_friendly_event_name = {\n",
    "    \"IssueCommentEvent-created\" : \"Issue Comment\",\n",
    "\t\"IssuesEvent-closed\" : \"Issue Close\",\n",
    "\t\"IssuesEvent-opened\" : \"Issue Open\",\n",
    "\t\"IssuesEvent-reopened\" : \"Issue Reopen\",\n",
    "\t\"PullRequestEvent-closed\" : \"PR Close\",\n",
    "\t\"PullRequestEvent-opened\" : \"PR Open\",\n",
    "\t\"PullRequestEvent-reopened\" : \"PR Reopen\",\n",
    "\t\"PullRequestReviewCommentEvent-created\" : \"PR Comment\",\n",
    "\t\"PullRequestReviewEvent-created\" : \"PR Review\",\n",
    "\t\"ReleaseEvent-published\" : \"Release Publish\",\n",
    "}\n",
    "\n",
    "# Define a function to add a new column based on row values\n",
    "# This is so get human friendly \"event_type\" + \"action\" strings\n",
    "def get_friendly_event_name(row):\n",
    "    # Access values of specific columns in the row\n",
    "    friendly_name = row['event_type'] + \"-\" + row['action']\n",
    "    return mapping_to_friendly_event_name.get(friendly_name, friendly_name)\n",
    "\n",
    "# Apply the function to each row and assign the result to a new column\n",
    "df['friendly_event_name'] = df.apply(lambda row: get_friendly_event_name(row), axis=1)\n",
    "\n",
    "df.to_csv(f\"{output_directory}/github-event-data-cleaned-{report_date_str}.csv\")\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.pivot_table(df.reset_index(), \n",
    "                               index=['org', 'repository_name', 'actor', 'year_quarter', 'year_month', 'friendly_event_name'], \n",
    "                               values='github_id', \n",
    "                               aggfunc='count',\n",
    "                               fill_value=0)\n",
    "\n",
    "summary_table.rename(columns={'github_id': 'count'}, inplace=True)\n",
    "\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table.to_csv(f\"{output_directory}/github-event-monthly-summary-{report_date_str}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_table = pd.pivot_table(df.reset_index(), \n",
    "                               index=['year_month'], \n",
    "                               columns=['org'],\n",
    "                               values='github_id', \n",
    "                               aggfunc='count',\n",
    "                               fill_value=0)\n",
    "\n",
    "audit_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_table.to_csv(f\"{output_directory}/github-event-monthly-summary-audit-{report_date_str}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
